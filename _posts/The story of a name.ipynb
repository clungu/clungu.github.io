{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The company that I'm currently working at (its name is irrelevant as you'll see in a moment) is in the middle of a rebrading effort. One of the key components in this is finding a better name for the company!\n",
    "\n",
    "The marketing department outlined a few likeliness topic to which the name should be associated with:\n",
    "* Mythology\n",
    "* Science\n",
    "* Succesfull organisation\n",
    "* AI\n",
    "\n",
    "The name should also be trademark-able and it's domains should be available for registration.\n",
    "\n",
    "With this knowledge in hand I've set out to conquer the challenge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I'm going to build an ML system that would generate the future name for our company!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem analisys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above forumulation needs a few clarifications (added by me) that would make the problem more specific:\n",
    "* We'll build an ML system that generates company names\n",
    "    * This alone will cover for the \"AI association\" requirement\n",
    "    \n",
    "* The geneated names should be:\n",
    "    * similar in style as to the following topics:\n",
    "        * Mythology\n",
    "        * Science\n",
    "        * Tech unicorn companies\n",
    "        * Fiction\n",
    "    * Plausible company names\n",
    "\n",
    "* The generated names should be unique (not duplicates of the training data)\n",
    "* The generated names should have an unregisterd .com domain\n",
    "* Given that this is a branding execise, marketing should have control over the stucture of the following name generation aspects:\n",
    "    * Length of the name\n",
    "    * Inclusion of specific sub string within the name\n",
    "    * Starting first letter of the name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, we need names datasets for the following topics and I've settled for some quick proxies:\n",
    "* Mythology - all Roman and Greek mythological figures as extracted from [here](https://www.npmjs.com/package/greek-mythology-data)\n",
    "* Science - all animals and birds names as extracted from [here](https://github.com/species-names)\n",
    "* Tech unicorn companies - took the [organisations and companies](https://www.kaggle.com/kaggle/meta-kaggle#Organizations.csv) that submitted Kaggle competitions. Presumably these are current or future unicorns.\n",
    "* Fiction - all the Lord Of The Rings [characters](https://www.kaggle.com/mokosan/lord-of-the-rings-character-data/version/1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I want the generated names to also resemble some usual company names, and given the assumption that `most of these have names derived from familly names` (e.g. \"Johnson & Johnson\", \"Calvin Klein\", \"Merrill Lynch\", etc..) I've took the [US Census familly name dataset](http://www2.census.gov/topics/genealogy/1990surnames/dist.all.last) to augment the above datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having these datasets, I'll load them with pandas and show and show the first few of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abderites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acinonyx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acomys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acratocnus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Addax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Animals\n",
       "0   Abderites\n",
       "1    Acinonyx\n",
       "2      Acomys\n",
       "3  Acratocnus\n",
       "4       Addax"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "animals = pd.read_csv(\"animals.csv\", header=None, comment='#', names=[\"Animals\"])\n",
    "animals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surnames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Williams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Surnames\n",
       "0     Smith\n",
       "1   Johnson\n",
       "2  Williams\n",
       "3     Jones\n",
       "4     Brown"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "familly_names = pd.read_csv(\"familly_names.csv\", header=None, comment='#', names=[\"Surnames\"])\n",
    "familly_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Birds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abeillia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abroscopus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aburria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acanthagenys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acanthidops</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Birds\n",
       "0      Abeillia\n",
       "1    Abroscopus\n",
       "2       Aburria\n",
       "3  Acanthagenys\n",
       "4   Acanthidops"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds = pd.read_csv(\"birds.csv\", header=None, comment='#', names=[\"Birds\"])\n",
    "birds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mythology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calleis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harpocrates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xanthus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stilbon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mythology\n",
       "0      Calleis\n",
       "1       Epirus\n",
       "2  Harpocrates\n",
       "3      Xanthus\n",
       "4      Stilbon"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mythology = pd.read_csv(\"mythology.csv\", header=None, comment='#', names=[\"Mythology\"])\n",
    "mythology.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organisations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Figure Eight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaggle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last-Place Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CWILOC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Organisations\n",
       "0         Facebook\n",
       "1     Figure Eight\n",
       "2           Kaggle\n",
       "3  Last-Place Ltd.\n",
       "4           CWILOC"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organisations = pd.read_csv(\"kaggle_organisations.csv\", header=None, comment='#', sep=\"\\n\", names=[\"Organisations\"])\n",
    "organisations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aragorn Ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arwen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elrond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Celebrían</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elrohir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LOTR\n",
       "0  Aragorn Ii\n",
       "1       Arwen\n",
       "2      Elrond\n",
       "3   Celebrían\n",
       "4     Elrohir"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lotr = pd.read_csv(\"lotr_names.csv\", header=None, comment='#', names=[\"LOTR\"])\n",
    "lotr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Birds</th>\n",
       "      <th>Animals</th>\n",
       "      <th>Mythology</th>\n",
       "      <th>Surnames</th>\n",
       "      <th>Organisations</th>\n",
       "      <th>LOTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abeillia</td>\n",
       "      <td>Abderites</td>\n",
       "      <td>Calleis</td>\n",
       "      <td>Smith</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Aragorn Ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abroscopus</td>\n",
       "      <td>Acinonyx</td>\n",
       "      <td>Epirus</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Figure Eight</td>\n",
       "      <td>Arwen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aburria</td>\n",
       "      <td>Acomys</td>\n",
       "      <td>Harpocrates</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Kaggle</td>\n",
       "      <td>Elrond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acanthagenys</td>\n",
       "      <td>Acratocnus</td>\n",
       "      <td>Xanthus</td>\n",
       "      <td>Jones</td>\n",
       "      <td>Last-Place Ltd.</td>\n",
       "      <td>Celebrían</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acanthidops</td>\n",
       "      <td>Addax</td>\n",
       "      <td>Stilbon</td>\n",
       "      <td>Brown</td>\n",
       "      <td>CWILOC</td>\n",
       "      <td>Elrohir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Birds     Animals    Mythology  Surnames    Organisations  \\\n",
       "0      Abeillia   Abderites      Calleis     Smith         Facebook   \n",
       "1    Abroscopus    Acinonyx       Epirus   Johnson     Figure Eight   \n",
       "2       Aburria      Acomys  Harpocrates  Williams           Kaggle   \n",
       "3  Acanthagenys  Acratocnus      Xanthus     Jones  Last-Place Ltd.   \n",
       "4   Acanthidops       Addax      Stilbon     Brown           CWILOC   \n",
       "\n",
       "         LOTR  \n",
       "0  Aragorn Ii  \n",
       "1       Arwen  \n",
       "2      Elrond  \n",
       "3   Celebrían  \n",
       "4     Elrohir  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([birds, animals, mythology, familly_names, organisations, lotr], axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, everything look nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training anything we need to make sure we understand our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off is to see how many names in each category do we have. This is important because if one of them is way larger than the others it would skew the ML model to generate data that resembles that at the expense of the other categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f501bcf65f8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAE3CAYAAABB1I0LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAGrtJREFUeJzt3X28ZmVd7/HPlxlRk3iSiRTIwcQH1FSYFDU7KoagFmg+QCmTcuScQk3PeVXYqYNaetQ6WXbUDkdQoJKI7CUpSoioZYEMSCAPxhzMgMPDKE8aGQ7+zh/rmuZmrhnm3jObvfbm/rxfr/3a97rWuu/92zfD/t7rWtd1rVQVkiRN2mHsAiRJi4/hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpM7ysQvYVnvssUetXLly7DIkacm4+OKLv1lVK6Y5dsmGw8qVK1mzZs3YZUjSkpHkG9Mea7eSJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOkt2EpwkLZQP/OfPjV0CAMf90fMX7Gd55iBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6hgOkqSO4SBJ6kwVDknekuSKJF9N8rEkD0myb5ILk6xN8mdJdmzHPrhtr237V068zltb+9eSvHCi/dDWtjbJ8fP9S0qS5mar4ZBkL+BNwKqqehKwDDgSeA/wvqp6DHAbcEx7yjHAba39fe04kuzfnvdE4FDgg0mWJVkGfAA4DNgfOKodK0kaybTdSsuBhyZZDvwAcCPwfODMtv8U4Ij2+PC2Tdt/cJK09tOr6t+q6uvAWuDp7WttVV1bVXcDp7djJUkj2Wo4VNUNwO8C/8wQCncAFwO3V9X6dtj1wF7t8V7Ade2569vxD59s3+Q5W2rvJDk2yZoka9atWzfN7ydJ2gbTdCvtxvBJfl/gkcDDGLqFFlxVnVhVq6pq1YoVK8YoQZJmwjTdSi8Avl5V66rqe8DHgWcDu7ZuJoC9gRva4xuAfQDa/l2Ab022b/KcLbVLkkYyTTj8M3BQkh9o1w4OBq4Ezgde3o5ZDXyiPT6rbdP2f66qqrUf2UYz7QvsB3wZuAjYr41+2pHhovVZ2/+rSZK21fKtHVBVFyY5E7gEWA98BTgR+BRwepLfbm0ntaecBJyWZC1wK8Mfe6rqiiRnMATLeuC4qroHIMkbgHMYRkKdXFVXzN+vKEmaq62GA0BVnQCcsEnztQwjjTY99rvAK7bwOu8E3rmZ9rOBs6epRZJ0/3OGtCSpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpM1U4JNk1yZlJrk5yVZJnJtk9yblJrmnfd2vHJsn7k6xNclmSAyZeZ3U7/pokqyfaD0xyeXvO+5Nk/n9VSdK0pj1z+APgM1X1eOApwFXA8cB5VbUfcF7bBjgM2K99HQt8CCDJ7sAJwDOApwMnbAiUdszrJ5536Pb9WpKk7bHVcEiyC/CTwEkAVXV3Vd0OHA6c0g47BTiiPT4cOLUGFwC7JnkE8ELg3Kq6tapuA84FDm37dq6qC6qqgFMnXkuSNIJpzhz2BdYBH0nylSQfTvIwYM+qurEdcxOwZ3u8F3DdxPOvb2331X79ZtolSSOZJhyWAwcAH6qqpwH/wsYuJADaJ/6a//LuLcmxSdYkWbNu3br7+8dJ0syaJhyuB66vqgvb9pkMYXFz6xKifb+l7b8B2Gfi+Xu3tvtq33sz7Z2qOrGqVlXVqhUrVkxRuiRpW2w1HKrqJuC6JI9rTQcDVwJnARtGHK0GPtEenwUc3UYtHQTc0bqfzgEOSbJbuxB9CHBO23dnkoPaKKWjJ15LkjSC5VMe90bgT5LsCFwLvJYhWM5IcgzwDeCV7dizgRcBa4G72rFU1a1Jfgu4qB33jqq6tT3+JeCjwEOBT7cvSdJIpgqHqroUWLWZXQdv5tgCjtvC65wMnLyZ9jXAk6apRZJ0/3OGtCSpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjpTh0OSZUm+kuSTbXvfJBcmWZvkz5Ls2Nof3LbXtv0rJ17jra39a0leONF+aGtbm+T4+fv1JEnbYi5nDr8MXDWx/R7gfVX1GOA24JjWfgxwW2t/XzuOJPsDRwJPBA4FPtgCZxnwAeAwYH/gqHasJGkkU4VDkr2BFwMfbtsBng+c2Q45BTiiPT68bdP2H9yOPxw4var+raq+DqwFnt6+1lbVtVV1N3B6O1aSNJJpzxx+H/hV4Ptt++HA7VW1vm1fD+zVHu8FXAfQ9t/Rjv/39k2es6X2TpJjk6xJsmbdunVTli5JmquthkOSlwC3VNXFC1DPfaqqE6tqVVWtWrFixdjlSNID1vIpjnk28DNJXgQ8BNgZ+ANg1yTL29nB3sAN7fgbgH2A65MsB3YBvjXRvsHkc7bULkkawVbPHKrqrVW1d1WtZLig/Lmq+nngfODl7bDVwCfa47PaNm3/56qqWvuRbTTTvsB+wJeBi4D92uinHdvPOGtefjtJ0jaZ5sxhS34NOD3JbwNfAU5q7ScBpyVZC9zK8MeeqroiyRnAlcB64LiqugcgyRuAc4BlwMlVdcV21CVJ2k5zCoeq+jzw+fb4WoaRRpse813gFVt4/juBd26m/Wzg7LnUIkm6/zhDWpLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLUMRwkSR3DQZLU2Wo4JNknyflJrkxyRZJfbu27Jzk3yTXt+26tPUnen2RtksuSHDDxWqvb8dckWT3RfmCSy9tz3p8k98cvK0mazjRnDuuB/1pV+wMHAccl2R84HjivqvYDzmvbAIcB+7WvY4EPwRAmwAnAM4CnAydsCJR2zOsnnnfo9v9qkqRttdVwqKobq+qS9vjbwFXAXsDhwCntsFOAI9rjw4FTa3ABsGuSRwAvBM6tqlur6jbgXODQtm/nqrqgqgo4deK1JEkjmNM1hyQrgacBFwJ7VtWNbddNwJ7t8V7AdRNPu7613Vf79ZtplySNZOpwSLIT8BfAm6vqzsl97RN/zXNtm6vh2CRrkqxZt27d/f3jJGlmTRUOSR7EEAx/UlUfb803ty4h2vdbWvsNwD4TT9+7td1X+96bae9U1YlVtaqqVq1YsWKa0iVJ22Ca0UoBTgKuqqrfm9h1FrBhxNFq4BMT7Ue3UUsHAXe07qdzgEOS7NYuRB8CnNP23ZnkoPazjp54LUnSCJZPccyzgdcAlye5tLX9OvBu4IwkxwDfAF7Z9p0NvAhYC9wFvBagqm5N8lvARe24d1TVre3xLwEfBR4KfLp9SZJGstVwqKq/BbY07+DgzRxfwHFbeK2TgZM3074GeNLWapEkLQxnSEuSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOsvHLkCLwNt2GbuCwdvuGLsCSc2iCYckhwJ/ACwDPlxV7x65JM2gJ5/y5LFLAODy1ZePXQJXPf4JY5cAwBOuvmrsEmbSouhWSrIM+ABwGLA/cFSS/cetSpJm12I5c3g6sLaqrgVIcjpwOHDl/fUDVx7/qfvrpefkn9794rFLkKROqmrsGkjycuDQqvqPbfs1wDOq6g2bHHcscGzbfBzwtQUttLcH8M2Ra1gsfC828r3YyPdio8XwXjyqqlZMc+BiOXOYSlWdCJw4dh0bJFlTVavGrmMx8L3YyPdiI9+LjZbae7EorjkANwD7TGzv3dokSSNYLOFwEbBfkn2T7AgcCZw1ck2SNLMWRbdSVa1P8gbgHIahrCdX1RUjlzWNRdPFtQj4Xmzke7GR78VGS+q9WBQXpCVJi8ti6VaSJC0ihoMkqWM4SJI6hoMkqWM4zEGSH03y4Pb4uUnelGTXsevS+JK8McluY9ehxSXJK5L8YHv8G0k+nuSAseuahuEwN38B3JPkMQzD0vYB/nTcksaT5L1Jdk7yoCTnJVmX5NVj1zWSPYGLkpyR5NAkGbugMST55fZvIklOSnJJkkPGrmtEv1lV307yE8ALgJOAD41c01QMh7n5flWtB14K/GFV/QrwiJFrGtMhVXUn8BLgn4DHAL8yakUjqarfAPZj+J//F4BrkrwryY+OWtjCe137N3EIsBvwGmCWl9+/p31/MXBiVX0K2HHEeqZmOMzN95IcBawGPtnaHjRiPWPbMInyxcCfV9VM362nhklDN7Wv9Qx/HM9M8t5RC1tYG86YXgSc1iazzuRZVHNDkv8NvAo4u3VLL4m/u0uiyEXktcAzgXdW1deT7AucNnJNY/pkkquBA4HzkqwAvjtyTaNo3SkXA+8FvgQ8uap+keG9+dlRi1tYFyf5a4ZwOKf1t39/5JrG9EqGlR9eWFW3A7uzRM6unSGt7ZJkd+COqronycOAH6yqm8aua6EleTvDsi/f2My+J1TVTNzOLMkOwFOBa6vq9iQPB/aqqstGLm007XrDflX1kfYBaqeq+vrYdW2N4TCFJJcDW3yjqurHFrCc0SV52X3tr6qPL1Qti0ULyU19u6q+t+DFjCzJXsCjmFi7raq+OF5F40lyArAKeFxVPTbJIxm6YJ89cmlbtSgW3lsCXjJ2AYvMT7fvPwQ8C/hc234e8HfAzIUDcAnD6LXbGPrYdwVuSnIz8PqqunjM4hZKkvcw9K9fycaLsQXMZDgwDF55GsO/D6rq/20Y2rrYGQ5T2FxXwSyrqtcCtL7l/avqxrb9COCjI5Y2pnOBM6vqHIA2fPNngY8AHwSeMWJtC+kIhk/J/zZ2IYvE3VVVSQqgdb0uCV6QnoMkByW5KMl3ktyd5J4kd45d14j22RAMzc3Aj4xVzMgO2hAMAFX118Azq+oC4MHjlbXgrmW2R/Bt6ow2WmnXJK8HPgv8n5FrmopnDnPzvxhuRPTnDP2IRwOPHbWicZ2X5BzgY237VQz/+GfRjUl+DTi9bb8KuDnJMmZrtM5dwKVJzgP+/eyhqt40XknjqarfTfJTwJ0M973/71V17shlTcUL0nOw4R6wSS7bcBE6yVeq6mlj1zaWJC8FfrJtfrGq/nLMesaSZA/gBOAnWtOXgLcDdwA/UlVrx6ptISVZvbn2qjploWtZTJLszL0v0N86YjlTMRzmIMkXGabAf5hhotONwC9U1VNGLWwE7RPxZ6vqeWPXspi0i41VVd8Zu5axtFv9bjij/tosjtjaIMl/YviQ8F2GM8gw/Pt49KiFTcFwmIMkjwJuYehTfQuwC/DBWflUuKnWdfCyWZ8ZDZDkycCpDJOcAL4JrK6qr45X1cJL8lzgFIblVMIwgmv1DA9lvYbh2tM3x65lrgwHbbMkn2AYpncu8C8b2mexfznJ3wH/rarOb9vPBd5VVc8atbAF1maJ/1xVfa1tPxb4WFUdOG5l40jyGYYPUHeNXctceUF6DpK8BPgtNk7w2XCKuPOohY3n48zmnIbNediGYACoqs8vpWGL8+hBG4IBoKr+Mcksj156K/B3SS5kiV2g98xhDpKsBV4GXF6+cZqQ5C8ZJjptWGvr1cCBVfXS8apaeElOZuhb/+PW9PPAsqp63XhVjSfJl4G/BS5nYtTaUrhAbzjMQZLzgYOrapaGJnaSnFFVr9zSsiKztpwIQLvRz9vZOFrpb4C3VdVt41W18Nqqo8dx7/fhg7M6KW4pj2Y0HOYgyY8zdCt9gXufIv7eaEWNIMkjqurGdoG+44xyaZDkXQwX5/+Ke//NcCjrA0lbLuI79KeIbx+tqEWijfP/1qx1tyX5K+57UcafWcByRuPZ5OYl2dzqqw5lfaBJ8tWqetLYdYwtyUEMd/e6leFM6jRgD4blWI6uqs+MWN6CSvIf7mt/VX1hoWoZk2eTDzyGwxy0O3p9tq2bM7OSrAF+nWGex4nAYVV1QZLHMwxbXJJ9rNvLyV/DqqxV9Wtba5slSZ4E7A88ZENbVZ06XkXTMRzmIMm3gYcx9B1+jxkdyprk0qp6ant8VVU9YWLfkr0Atz2c/DVIcklVHbBJ22Uz3K10AvBchnA4GzgM+NuqevmYdU3DeQ5zUFVLYh32BTA5WutfN9k3q582/idwyKaTvxhuE/qAl+QXgV8CHp1k8q5vP8iwztSsejnwFOArVfXaJHuycZjvomY4TCHJ46vq6iQHbG5/VV2y0DWN7CltqfIAD51YtjxMnDrPmFmf/PWnwKeB/wEcP9H+7aUwMud+9K9V9f0k69vie7cwnFUueobDdP4LcCzDp8NNFfD8hS1nXFW1bOwaFqE1ST7MvSd/rRmxngXV1te6AzgKIMkPMXxQ2CnJTlX1z2PWN6I1SXZluIfDxQyjHf9+3JKm4zUHaR44+WuQ5KeB3wMeyfAp+VHAVVX1xFELWwSSrAR2rqrLtnLoomA4zFGSZwEruffa7It+5IG0EJL8A8OZ9Ger6mlJnge8uqqOGbm00STZi43rsQGwFAYq2K00B0lOA34UuJR73zzdcJhxSZ4NvI3+j8Cin+w0z75XVd9KskOSHarq/CS/P3ZRY0nyHoa7Al7Jvf9mGA4PMKuA/WdtFrCmchLDPT4uZuMfgVl0e5KdGP74/UmSW5hYzn0GHQE8bil2LxoOc/NV4IcZ7gAnTbqjqj49dhGLwOEMw5vfwnBRfhfgHaNWNK5rGW4OZjg8wO0BXNmW4d3wH7uq6vARa9KIJoY3n5/kdxjubzG5wNqsDXMGoKrWJ/l74PHAnVs7/gHsLuDSdtdE7+fwQLXJOjoBngMc6UiM2dWWcd+SqqqZGubc7gT3HGA3hslvFwF3V9XPj1rYSJKs3lz7Urifg2cOc1BVX0jyNODngFcAXwf+aNyqNKaqeh5AkkdX1bWT+5LM2sVoGD5w3pXkGIahvO9NcunYRY0hyTKGWfNLMhgNhym0pRCOal/fBP6M4X+C541amBaTM4FNZ9D/OTOyfMaEJHkmw/WGDcNXZ3LSZFXdk+RRSXasqrvHrmeuDIfpXM0wqeklVbUWIMlbxi1Ji0FbifaJwC5JXjaxa2dmcymRNzPcN/kvq+qKdvZ0X11vD3TXAl9KchYTo7aWwg3CDIfpvAw4kuGi42eA0xmuOUiPA14C7Ar89ET7t4HXj1LRiNr9K74wsX0tsOgvvt6P/m/72oFhEcIlwwvSc5DkYQxD9Y5imAV6KsMnpJm+v4MgyXOq6m/GrmMsSX6/qt68pTvjzcod8R5IDIdt1G4o/wrgVVV18Nj1aFxJrmGYOf8R4NOzNlEyyYFVdfGW7ow3K3fE21Qbzba5sFz0o9gMB2keJAnwAuB1wI8DZwAfrap/HLUwjSrJ5ICEhwA/C6yvql8dqaSpGQ7SPGuLzf0xw10D/wE4vqqWxDLN22sza0xtuFviLA7r3awkX66qp49dx9Z4QVqaB0keDrwaeA1wM/BG4CzgqQxDWvcdr7oF5RpTE5LsPrG5A8P6bLuMVM6cGA7S/Ph74DTgiKq6fqJ9TZJZmijpGlP3djEbrzmsZ7jH+JJYvtxuJWkeJMmsXYTenCTvZpj0NtNrTCX5ceC6qrqpba9muN7wT8DblsKtUw0HaTu0yU1bNGtDOLew1tQsrjF1CfCCqro1yU8yzI16I0M34xOq6uWjFjgFw0HaDknWAdcBHwMuZJPJkbM6hHPWJfmHqnpKe/wBYF1Vva1tX1pVTx2zvml4zUHaPj8M/BTDxMifAz4FfKyqrhi1qhEleTHDkiL/vnxIVc3aPR2WJVleVeuBg4FjJ/Ytib+7O4xdgLSUVdU9VfWZqloNHASsBT6f5A0jlzaKdvH9VQxdKGGYKPqoUYsax8eALyT5BMPNj/4GIMljgDvGLGxaditJ2ynJg4EXM5w9rGQYwnpyVd0wZl1jSHJZVf3YxPedGGaMP2fs2hZakoOARwB/XVX/0toeC+y0FC7QL4nTG2mxSnIq8CTgbODtVfXVkUsa27+273cleSTwLYY/kDOnqi7YTNuSmTHvmYO0HZJ8n41LMU/+z7RhZvDOC1/VeJL8JvCHDP3sH2B4Tz5cVb85amGaM8NB0v2idbc9pKqWRB+77s1wkDRvNrnh0QZ3AJdX1S0LXY+2neEgad4k+RTwTDbe/e25DEtI7Au8o6pOG6k0zZEXpCXNp+UMM4BvBkiyJ8NNsZ4BfJFh/SktAc5zkDSf9tkQDM0tre1W4Hsj1aRt4JmDpPn0+SSfZFimHIbF5j7fbrF7+3hlaa685iBp3rQ74r0M+InW9CXgL1yxdukxHCTNiyTLgM9W1fPGrkXbz2sOkuZFVd0DfD/JkrjTme6b1xwkzafvAJcnOZeNM8epqjeNV5K2heEgaT59Bvgsw7IZ69m41pKWGMNB0nZLshx4F/A64BsMa0v9CPAR4NdHLE3byGsOkubD7wC7A/tW1YFVdQDwaGCXtk9LjKOVJG23JNcAj910yGobwXR1Ve03TmXaVp45SJoPtbm5DG0Ek59AlyDDQdJ8uDLJ0Zs2Jnk1cPUI9Wg72a0kabsl2Qv4OMPopItb8yrgocBLZ/GWqUud4SBp3iR5PvDEtnllVZ03Zj3adoaDJKnjNQdJUsdwkCR1DAdJUsdwkCR1/j+qqnRb6qdvugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "everything = pd.concat([animals, birds, mythology, organisations, familly_names], axis=1)\n",
    "everything.count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's evident from the above graph that the familly names datases is way larger than the other ones. We don't want it to be more represented than the other categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to compute the median of all the counts. This value will tell us how many samples to take from each category and is a middle ground between the ones that have few names and the ones that have lots of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1588"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median = int(np.median((len(animals), len(birds), len(mythology), len(organisations), len(familly_names))))\n",
    "median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because some collections have fewer than `median` elements, we need to sample with `replace=True` (this will add duplicates). In this step we'll also concatenate everything into one large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9528, 1)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_names = np.concatenate((\n",
    "    animals.sample(n=median, replace=True),\n",
    "    birds.sample(n=median, replace=True),\n",
    "    mythology.sample(n=median, replace=True),\n",
    "    organisations.sample(n=median, replace=True),\n",
    "    familly_names.sample(n=median, replace=True),\n",
    "    lotr.sample(n=median, replace=True),\n",
    "))\n",
    "all_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! 10k names isn't that bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some examples of the resulting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Thylacoleo'],\n",
       "       ['Odocoileus'],\n",
       "       ['Liberiictis'],\n",
       "       ['Carpitalpa'],\n",
       "       ['Hesperaletes'],\n",
       "       ['Cricetomys'],\n",
       "       ['Chrotopterus'],\n",
       "       ['Thylacoleo'],\n",
       "       ['Macrogalidia'],\n",
       "       ['Kenyatherium']], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_names[90:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminating lengthy outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible that our names dataset contain some really large, lengthy names. And it's almost certain that these will be outliers for the full data. If this is the case, we'll need to eliminate them and only deal with the common average names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll printing a name length statistics to see how lengths are represented in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>Podogymnura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>Myotragus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Balaenoptera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Pseudorca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Nurocyon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length          Name\n",
       "0      11   Podogymnura\n",
       "1       9     Myotragus\n",
       "2      12  Balaenoptera\n",
       "3       9     Pseudorca\n",
       "4       8      Nurocyon"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_pd = pd.DataFrame([[len(name), name] for [name] in all_names], columns=[\"Length\", \"Name\"])\n",
    "length_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outliers that we're seeking should be in the high percentiles, so we'll print the pandas statistics of the DataFrame adding those percentiles as well. By default, pandas only includes the `[.25, .50, .75]` percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9528.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.419395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>51.586712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2859.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Length\n",
       "count  9528.000000\n",
       "mean     10.419395\n",
       "std      51.586712\n",
       "min       2.000000\n",
       "50%       8.000000\n",
       "90%      14.000000\n",
       "95%      17.000000\n",
       "99%      32.000000\n",
       "max    2859.000000"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_pd.describe(percentiles=[.90, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 99% of the data has less than 33 chars, but the maximum name in it is 2859 chars! We should actually see what's with this large name and find out how many of these we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,    3,    4,    5,    6,    7,    8,    9,   10,   11,   12,\n",
       "         13,   14,   15,   16,   17,   18,   19,   20,   21,   22,   23,\n",
       "         24,   25,   26,   27,   28,   29,   30,   31,   32,   33,   34,\n",
       "         35,   36,   37,   38,   39,   40,   41,   42,   43,   44,   45,\n",
       "         46,   47,   48,   49,   50,  209,  595, 2859])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(length_pd.Length.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have some `{209, 595, 2859}` names. The rest of the buckets seem to be in a reasonable range. What are these large names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"/><h1>test</h1>\\nMindMatch\\nData Unicorns\\nmyOrganization\\nInfosys\\nRain City Casual\\nOnkar Kadam\\nMayflower\\nhttp://humbertobrandao.com\\nwecash\\nQueen's Centre for Advanced Computing\\npapuuuus\\nVinayagam\\n</title>A'><h1>X\",\n",
       " \"/><h1>test</h1>\\nMindMatch\\nData Unicorns\\nmyOrganization\\nInfosys\\nRain City Casual\\nOnkar Kadam\\nMayflower\\nhttp://humbertobrandao.com\\nwecash\\nQueen's Centre for Advanced Computing\\npapuuuus\\nVinayagam\\n</title>A'><h1>X\"]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for [name] in all_names if len(name) in {209, 595, 2859}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To me, these look like SQL Injection attempts on the Kaggle web-site.. I hope Kaggle fought them off. But the overall conclusion is that the bad apples come from the Kaggle organisations dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm unsure if we should spend more time cleaning the organisation names, but just to keep it simple, maybe we should drop the organisations, they seem the contain lots of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7940, 1)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_names = np.concatenate((\n",
    "    animals.sample(n=median, replace=True),\n",
    "    birds.sample(n=median, replace=True),\n",
    "    mythology.sample(n=median, replace=True),\n",
    "    familly_names.sample(n=median, replace=True),\n",
    "    lotr.sample(n=median, replace=True),\n",
    "))\n",
    "all_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing again the Length percentiles.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.462469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.901147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Length\n",
       "count  7940.000000\n",
       "mean      8.462469\n",
       "std       2.901147\n",
       "min       3.000000\n",
       "50%       8.000000\n",
       "90%      12.000000\n",
       "95%      14.000000\n",
       "99%      17.000000\n",
       "max      24.000000"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_pd = pd.DataFrame([[len(name), name] for [name] in all_names], columns=[\"Length\", \"Name\"])\n",
    "length_pd.describe(percentiles=[.90, .95, .99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the maximum name now is 24 chars long. I wonder what that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 'The Nymphai Hyperboreioi')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length, name = max([len(name), name] for [name] in all_names)\n",
    "max_length, name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems more reasonable now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model I'm building (as any other model) should receive numerical data, so we need a way to convert the strings to numerical representations. \n",
    "\n",
    "Usually this is done by a two-way datastructure that returns an unique id for a given char, and a char for a given id. \n",
    "\n",
    "This datastructure is called a vocabulary and we can quickly simulate one by using a list and a dictionary both synced on the same ids. \n",
    "\n",
    "In the vocabulary we will also need (at least) two special characters:\n",
    "* `PADD_CHAR` that will be used to convert inputs that are smaller than the fixed length required by a model\n",
    "* `STOP_CHAR` that will mark the end of a name\n",
    "\n",
    "There are other additional specials that you could add but this is beiond the point of this excercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, array(['|', '_', 'ï', 'i', 'g', 'n', 'S', 'h', 'G', 'M', 'm', 'B', 's',\n",
       "        'w', 'ä', 'â', 'ê', \"'\", 'E', 'o', 'O', 'Î', 'Í', 'N', 'û', '\\xad',\n",
       "        'd', 'H', 'b', 'V', 'R', 'Z', 'ë', 'í', 'C', 'D', 'ó', 'a', 'z',\n",
       "        'f', 'r', 'T', 'K', 'c', 'ö', 'É', 'k', 'j', 'l', 'ú', 'e', 'y',\n",
       "        'Y', 'A', 'W', 'X', 'x', 'P', 'é', 'Ó', '-', 'J', 'ô', 'v', 'Q',\n",
       "        ' ', '.', 'I', 'á', 'F', 'U', 'u', 'q', 'p', 'L', 't'], dtype='<U1'))"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOP_CHAR = '|'\n",
    "PADD_CHAR = '_'\n",
    "id2voc = np.array([STOP_CHAR, PADD_CHAR] + list({char for [name] in all_names for char in name}))\n",
    "voc2id = {char: i for i, char in enumerate(id2voc)}\n",
    "voc_size = len(id2voc)\n",
    "voc_size, id2voc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will model the task as a prediction (classification to be more exact) problem, where given as input a sequence of n characters `[c1, c2, c3, .., c(n) ]` the aim of the model is to predict the next *plausible* character `c(n+1)`.\n",
    "\n",
    "For example if I have the following input: `Mari` the model should be able to predict that the next most probabile character is `a`. \n",
    "\n",
    "In this case, `n` will be called a `window_size` because we will treat each name in the training set as a sequence over which we will be sliding a moving window, treating the window contents as the input and the next char, comming right after the window, the target prediction.\n",
    "\n",
    "For example `Lochmias` will have the following windows and predictions:\n",
    "\n",
    "```inp y\n",
    "......\n",
    "   L o\n",
    "  Lo c\n",
    " Loc h\n",
    "Loch m\n",
    "ochm i\n",
    "chmi a\n",
    "hmia s```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use keras as is fast and eloquent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, LSTM, Bidirectional, Dropout, Dense, Embedding\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to stick with a window size of 4 but this is something of a guess-timate and can be tunned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not going to talk much about the model bellow as I guess most of the people comming here either understand what's happening already or the opposite, don't care about these.\n",
    "\n",
    "Suffice to say it's a character level, embeddings enabled RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 4, 50)             2950      \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 4, 60)             19440     \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 60)                21840     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 59)                3599      \n",
      "=================================================================\n",
      "Total params: 47,829\n",
      "Trainable params: 47,829\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(window_size,))\n",
    "emb = Embedding(input_dim=voc_size, output_dim=50)\n",
    "\n",
    "x = emb(inp)\n",
    "x = Bidirectional(LSTM(30, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(30, return_sequences=False))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(voc_size)(x)\n",
    "out = x\n",
    "\n",
    "model = Model(inputs=[inp], outputs=[out])\n",
    "model.summary()\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once everything is in place we could ideally proceed to the training phase but there's an additional step before that which is massaging the names dataset into the exact format that we need. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all is to have a propper `train, validation, test` split (with initial shuffling).\n",
    "\n",
    "We're going to split the data into 70% 15% 15% for each of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(all_names)\n",
    "perm = np.random.permutation(size)\n",
    "train = all_names[perm][:int(size*0.70)]\n",
    "valid = all_names[perm][int(size*0.70): int(size*0.85)]\n",
    "test = all_names[perm][int(size*0.85):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the data generators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras also needs data either in a list format or a generator that can yield batches of data one at a time. \n",
    "\n",
    "Either way, bellow you'll find lots of boiler plate code that may not look so interesting so feel free to skip righ to the `Train` section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 2, 3],\n",
       "       [2, 3, 4],\n",
       "       [3, 4, 5],\n",
       "       [4, 5, 6],\n",
       "       [5, 6, 7],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://gist.github.com/codehacken/708f19ae746784cef6e68b037af65788\n",
    "def rolling_window(a, window, step_size):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1 - step_size, window)\n",
    "    strides = a.strides + (a.strides[-1] * step_size,)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "rolling_window(np.arange(10), 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___L o\n",
      "__Lo c\n",
      "_Loc h\n",
      "Loch m\n",
      "ochm i\n",
      "chmi a\n",
      "hmia s\n",
      "mias |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Lochmias', None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_pad = [PADD_CHAR] * (window_size - 1) \n",
    "right_pad = [STOP_CHAR]\n",
    "\n",
    "def index(this_name):\n",
    "    return np.array([voc2id[char] for char in this_name])\n",
    "\n",
    "def window_name(name, window_size):\n",
    "    this_name = left_pad + list(name) + right_pad\n",
    "    iname = index(this_name)\n",
    "    windows = rolling_window(iname, window_size, 1)\n",
    "    y = np.array([iname[i] for i in range(window_size,len(iname))])\n",
    "    return windows, y\n",
    "    \n",
    "def convert(windows, y):\n",
    "    for i, wind in enumerate(windows):\n",
    "        print(\"\".join([id2voc[id] for id in wind]), id2voc[y[i]])\n",
    "    \n",
    "train[0][0], convert(*window_name(train[0][0], window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 3, 1, 2]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def loop(iterable, epochs):\n",
    "    def gen(l):\n",
    "        for element in l:\n",
    "            yield element\n",
    "\n",
    "    return chain(*([gen(iterable) for _ in range(epochs)]))\n",
    "\n",
    "data = loop([1, 2, 3], 3)\n",
    "[next(data) for _ in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_batch(names_gen, batch_size=64, n=None, window_size=4):\n",
    "    x_batch, y_batch = None, None\n",
    "    for [name] in names_gen:\n",
    "        windows, y = window_name(name, window_size)\n",
    "        assert y[-1] == 0\n",
    "        if x_batch is None:\n",
    "            x_batch = windows\n",
    "            y_batch = y\n",
    "        else:\n",
    "            x_batch = np.concatenate((\n",
    "                x_batch, \n",
    "                windows\n",
    "            ))\n",
    "            y_batch = np.concatenate((\n",
    "                y_batch,\n",
    "                y\n",
    "            ))\n",
    "        \n",
    "        while x_batch is not None and len(x_batch) >= batch_size:\n",
    "            if len(x_batch) > batch_size:\n",
    "                # with spill-over\n",
    "                yield x_batch[:batch_size], y_batch[:batch_size]\n",
    "                x_batch, y_batch = x_batch[batch_size:], y_batch[batch_size:]\n",
    "            elif len(x_batch) == batch_size:\n",
    "                # complete name fits in current batch\n",
    "                yield x_batch, y_batch\n",
    "                x_batch, y_batch = None, None\n",
    "        \n",
    "    \n",
    "g = generate_batch(train[:10], batch_size=4, n=10)\n",
    "\n",
    "[sum(y==0) for x, y in g]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[ 1,  1,  1, 57],\n",
       "         [ 1,  1, 57, 15],\n",
       "         [ 1, 57, 15, 56],\n",
       "         [57, 15, 56,  6],\n",
       "         [15, 56,  6,  9],\n",
       "         [56,  6,  9,  2],\n",
       "         [ 6,  9,  2, 28],\n",
       "         [ 9,  2, 28, 10],\n",
       "         [ 1,  1,  1, 45],\n",
       "         [ 1,  1, 45,  6],\n",
       "         [ 1, 45,  6,  2],\n",
       "         [45,  6,  2, 37],\n",
       "         [ 6,  2, 37, 28],\n",
       "         [ 2, 37, 28,  4],\n",
       "         [37, 28,  4, 58],\n",
       "         [28,  4, 58, 15],\n",
       "         [ 4, 58, 15,  9],\n",
       "         [58, 15,  9, 19],\n",
       "         [15,  9, 19, 28],\n",
       "         [ 1,  1,  1, 20],\n",
       "         [ 1,  1, 20, 38],\n",
       "         [ 1, 20, 38,  9],\n",
       "         [20, 38,  9,  2],\n",
       "         [38,  9,  2,  3],\n",
       "         [ 9,  2,  3,  4],\n",
       "         [ 2,  3,  4, 28],\n",
       "         [ 3,  4, 28, 58],\n",
       "         [ 4, 28, 58,  6],\n",
       "         [28, 58,  6, 54],\n",
       "         [58,  6, 54, 10],\n",
       "         [ 1,  1,  1, 25],\n",
       "         [ 1,  1, 25, 28],\n",
       "         [ 1, 25, 28, 37],\n",
       "         [25, 28, 37, 28],\n",
       "         [28, 37, 28,  4],\n",
       "         [37, 28,  4, 18],\n",
       "         [28,  4, 18, 31],\n",
       "         [ 4, 18, 31, 38],\n",
       "         [18, 31, 38, 37],\n",
       "         [31, 38, 37, 37],\n",
       "         [38, 37, 37, 28],\n",
       "         [ 1,  1,  1, 45],\n",
       "         [ 1,  1, 45, 39],\n",
       "         [ 1, 45, 39, 31],\n",
       "         [45, 39, 31, 31],\n",
       "         [39, 31, 31,  6],\n",
       "         [31, 31,  6,  2],\n",
       "         [31,  6,  2, 56],\n",
       "         [ 6,  2, 56,  6],\n",
       "         [ 2, 56,  6, 15],\n",
       "         [56,  6, 15, 10],\n",
       "         [ 1,  1,  1,  5],\n",
       "         [ 1,  1,  5, 28],\n",
       "         [ 1,  5, 28, 15],\n",
       "         [ 5, 28, 15,  4],\n",
       "         [ 1,  1,  1, 32],\n",
       "         [ 1,  1, 32, 38],\n",
       "         [ 1, 32, 38, 58],\n",
       "         [32, 38, 58,  6],\n",
       "         [38, 58,  6, 39],\n",
       "         [58,  6, 39, 10],\n",
       "         [ 1,  1,  1, 32],\n",
       "         [ 1,  1, 32, 38],\n",
       "         [ 1, 32, 38,  4]]),\n",
       "  array([15, 56,  6,  9,  2, 28, 10,  0,  6,  2, 37, 28,  4, 58, 15,  9, 19,\n",
       "         28,  0, 38,  9,  2,  3,  4, 28, 58,  6, 54, 10,  0, 28, 37, 28,  4,\n",
       "         18, 31, 38, 37, 37, 28,  0, 39, 31, 31,  6,  2, 56,  6, 15, 10,  0,\n",
       "         28, 15,  4,  0, 38, 58,  6, 39, 10,  0, 38,  4, 31])),\n",
       " (array([[32, 38,  4, 31],\n",
       "         [38,  4, 31, 38],\n",
       "         [ 4, 31, 38, 56],\n",
       "         [ 1,  1,  1, 27],\n",
       "         [ 1,  1, 27, 31],\n",
       "         [ 1, 27, 31, 15],\n",
       "         [27, 31, 15,  9],\n",
       "         [31, 15,  9, 28],\n",
       "         [15,  9, 28,  2],\n",
       "         [ 9, 28,  2, 54],\n",
       "         [28,  2, 54, 10],\n",
       "         [ 1,  1,  1, 42],\n",
       "         [ 1,  1, 42,  2],\n",
       "         [ 1, 42,  2,  4],\n",
       "         [42,  2,  4, 18],\n",
       "         [ 2,  4, 18,  2],\n",
       "         [ 4, 18,  2, 10],\n",
       "         [18,  2, 10, 56],\n",
       "         [ 2, 10, 56,  6],\n",
       "         [ 1,  1,  1,  7],\n",
       "         [ 1,  1,  7, 54],\n",
       "         [ 1,  7, 54,  4],\n",
       "         [ 1,  1,  1, 27],\n",
       "         [ 1,  1, 27,  2],\n",
       "         [ 1, 27,  2, 28],\n",
       "         [27,  2, 28,  4],\n",
       "         [ 2, 28,  4, 28],\n",
       "         [ 1,  1,  1,  8],\n",
       "         [ 1,  1,  8,  2],\n",
       "         [ 1,  8,  2, 37],\n",
       "         [ 8,  2, 37, 18],\n",
       "         [ 2, 37, 18, 31],\n",
       "         [37, 18, 31, 38],\n",
       "         [18, 31, 38,  4],\n",
       "         [ 1,  1,  1, 51],\n",
       "         [ 1,  1, 51, 15],\n",
       "         [ 1, 51, 15, 37],\n",
       "         [51, 15, 37, 38],\n",
       "         [ 1,  1,  1, 27],\n",
       "         [ 1,  1, 27,  2],\n",
       "         [ 1, 27,  2, 26],\n",
       "         [27,  2, 26, 15],\n",
       "         [ 2, 26, 15, 18],\n",
       "         [26, 15, 18, 15],\n",
       "         [15, 18, 15,  9],\n",
       "         [18, 15,  9, 39],\n",
       "         [15,  9, 39, 10],\n",
       "         [ 1,  1,  1, 22],\n",
       "         [ 1,  1, 22, 54],\n",
       "         [ 1, 22, 54, 12],\n",
       "         [22, 54, 12, 38],\n",
       "         [54, 12, 38,  4],\n",
       "         [12, 38,  4, 29],\n",
       "         [38,  4, 29, 15],\n",
       "         [ 4, 29, 15, 31],\n",
       "         [29, 15, 31,  2],\n",
       "         [15, 31,  2, 10],\n",
       "         [31,  2, 10, 15],\n",
       "         [ 2, 10, 15, 31],\n",
       "         [10, 15, 31, 38],\n",
       "         [15, 31, 38, 44],\n",
       "         [ 1,  1,  1, 45],\n",
       "         [ 1,  1, 45, 28],\n",
       "         [ 1, 45, 28,  4]]),\n",
       "  array([38, 56,  0, 31, 15,  9, 28,  2, 54, 10,  0,  2,  4, 18,  2, 10, 56,\n",
       "          6,  0, 54,  4,  0,  2, 28,  4, 28,  0,  2, 37, 18, 31, 38,  4,  0,\n",
       "         15, 37, 38,  0,  2, 26, 15, 18, 15,  9, 39, 10,  0, 54, 12, 38,  4,\n",
       "         29, 15, 31,  2, 10, 15, 31, 38, 44,  0, 28,  4, 18])),\n",
       " (array([[45, 28,  4, 18],\n",
       "         [28,  4, 18, 28],\n",
       "         [ 4, 18, 28, 31],\n",
       "         [18, 28, 31, 38],\n",
       "         [28, 31, 38, 54],\n",
       "         [31, 38, 54, 10],\n",
       "         [ 1,  1,  1,  8],\n",
       "         [ 1,  1,  8, 28],\n",
       "         [ 1,  8, 28, 56],\n",
       "         [ 8, 28, 56, 31],\n",
       "         [28, 56, 31, 15],\n",
       "         [56, 31, 15,  3],\n",
       "         [31, 15,  3, 28],\n",
       "         [15,  3, 28, 37],\n",
       "         [ 3, 28, 37,  2],\n",
       "         [28, 37,  2, 18],\n",
       "         [37,  2, 18,  2],\n",
       "         [ 2, 18,  2, 28],\n",
       "         [ 1,  1,  1, 16],\n",
       "         [ 1,  1, 16, 31],\n",
       "         [ 1, 16, 31, 56],\n",
       "         [16, 31, 56,  2],\n",
       "         [31, 56,  2,  4],\n",
       "         [56,  2,  4, 54],\n",
       "         [ 2,  4, 54, 10],\n",
       "         [ 1,  1,  1, 32],\n",
       "         [ 1,  1, 32, 39],\n",
       "         [ 1, 32, 39, 31],\n",
       "         [32, 39, 31, 28],\n",
       "         [39, 31, 28,  4],\n",
       "         [31, 28,  4,  4],\n",
       "         [28,  4,  4, 54],\n",
       "         [ 4,  4, 54, 10],\n",
       "         [ 1,  1,  1, 45],\n",
       "         [ 1,  1, 45, 15],\n",
       "         [ 1, 45, 15, 37],\n",
       "         [45, 15, 37, 39],\n",
       "         [15, 37, 39, 10],\n",
       "         [37, 39, 10, 58],\n",
       "         [39, 10, 58, 31],\n",
       "         [10, 58, 31, 28],\n",
       "         [58, 31, 28, 58],\n",
       "         [31, 28, 58, 54],\n",
       "         [28, 58, 54, 10],\n",
       "         [ 1,  1,  1,  8],\n",
       "         [ 1,  1,  8, 38],\n",
       "         [ 1,  8, 38, 10],\n",
       "         [ 8, 38, 10, 58],\n",
       "         [38, 10, 58, 31],\n",
       "         [10, 58, 31, 28],\n",
       "         [ 1,  1,  1,  8],\n",
       "         [ 1,  1,  8, 28],\n",
       "         [ 1,  8, 28,  4],\n",
       "         [ 8, 28,  4,  2],\n",
       "         [ 1,  1,  1, 14],\n",
       "         [ 1,  1, 14, 31],\n",
       "         [ 1, 14, 31,  2],\n",
       "         [14, 31,  2, 58],\n",
       "         [31,  2, 58, 31],\n",
       "         [ 2, 58, 31, 38],\n",
       "         [58, 31, 38, 54],\n",
       "         [31, 38, 54,  9],\n",
       "         [ 1,  1,  1, 25],\n",
       "         [ 1,  1, 25, 15]]),\n",
       "  array([28, 31, 38, 54, 10,  0, 28, 56, 31, 15,  3, 28, 37,  2, 18,  2, 28,\n",
       "          0, 31, 56,  2,  4, 54, 10,  0, 39, 31, 28,  4,  4, 54, 10,  0, 15,\n",
       "         37, 39, 10, 58, 31, 28, 58, 54, 10,  0, 38, 10, 58, 31, 28,  0, 28,\n",
       "          4,  2,  0, 31,  2, 58, 31, 38, 54,  9,  0, 15, 31])),\n",
       " (array([[ 1, 25, 15, 31],\n",
       "         [25, 15, 31, 56],\n",
       "         [15, 31, 56, 15],\n",
       "         [31, 56, 15, 31],\n",
       "         [56, 15, 31, 28],\n",
       "         [15, 31, 28, 44],\n",
       "         [ 1,  1,  1,  7],\n",
       "         [ 1,  1,  7, 39],\n",
       "         [ 1,  7, 39,  9],\n",
       "         [ 7, 39,  9,  4],\n",
       "         [39,  9,  4, 15],\n",
       "         [ 9,  4, 15,  9],\n",
       "         [ 4, 15,  9, 39],\n",
       "         [15,  9, 39, 29],\n",
       "         [ 9, 39, 29, 28],\n",
       "         [ 1,  1,  1, 53],\n",
       "         [ 1,  1, 53, 28],\n",
       "         [ 1, 53, 28, 58],\n",
       "         [53, 28, 58, 38],\n",
       "         [28, 58, 38, 10],\n",
       "         [ 1,  1,  1, 17],\n",
       "         [ 1,  1, 17, 38],\n",
       "         [ 1, 17, 38, 15],\n",
       "         [17, 38, 15, 56],\n",
       "         [38, 15, 56, 31],\n",
       "         [15, 56, 31, 38],\n",
       "         [56, 31, 38, 44],\n",
       "         [ 1,  1,  1,  8],\n",
       "         [ 1,  1,  8, 39],\n",
       "         [ 1,  8, 39, 31],\n",
       "         [ 8, 39, 31, 58],\n",
       "         [39, 31, 58, 15],\n",
       "         [ 1,  1,  1, 25],\n",
       "         [ 1,  1, 25, 39],\n",
       "         [ 1, 25, 39, 18],\n",
       "         [25, 39, 18,  2],\n",
       "         [39, 18,  2, 26],\n",
       "         [18,  2, 26, 26],\n",
       "         [ 2, 26, 26, 38],\n",
       "         [ 1,  1,  1, 25],\n",
       "         [ 1,  1, 25, 37],\n",
       "         [ 1, 25, 37, 39],\n",
       "         [25, 37, 39, 58],\n",
       "         [37, 39, 58, 15],\n",
       "         [39, 58, 15, 31],\n",
       "         [58, 15, 31,  6],\n",
       "         [15, 31,  6, 39],\n",
       "         [31,  6, 39,  4],\n",
       "         [ 6, 39,  4, 56],\n",
       "         [39,  4, 56,  6],\n",
       "         [ 4, 56,  6, 54],\n",
       "         [56,  6, 54, 10],\n",
       "         [ 1,  1,  1, 45],\n",
       "         [ 1,  1, 45, 31],\n",
       "         [ 1, 45, 31, 15],\n",
       "         [45, 31, 15, 28],\n",
       "         [31, 15, 28, 26],\n",
       "         [15, 28, 26, 58],\n",
       "         [28, 26, 58, 38],\n",
       "         [26, 58, 38, 31],\n",
       "         [58, 38, 31, 39],\n",
       "         [38, 31, 39, 44],\n",
       "         [ 1,  1,  1, 16],\n",
       "         [ 1,  1, 16, 54]]),\n",
       "  array([56, 15, 31, 28, 44,  0, 39,  9,  4, 15,  9, 39, 29, 28,  0, 28, 58,\n",
       "         38, 10,  0, 38, 15, 56, 31, 38, 44,  0, 39, 31, 58, 15,  0, 39, 18,\n",
       "          2, 26, 26, 38,  0, 37, 39, 58, 15, 31,  6, 39,  4, 56,  6, 54, 10,\n",
       "          0, 31, 15, 28, 26, 58, 38, 31, 39, 44,  0, 54, 31])),\n",
       " (array([[ 1, 16, 54, 31],\n",
       "         [16, 54, 31, 38],\n",
       "         [54, 31, 38, 19],\n",
       "         [31, 38, 19,  2],\n",
       "         [38, 19,  2, 28],\n",
       "         [ 1,  1,  1, 41],\n",
       "         [ 1,  1, 41, 18],\n",
       "         [ 1, 41, 18, 38],\n",
       "         [41, 18, 38, 39],\n",
       "         [18, 38, 39, 38],\n",
       "         [38, 39, 38,  9],\n",
       "         [39, 38,  9, 15],\n",
       "         [ 1,  1,  1, 20],\n",
       "         [ 1,  1, 20, 38],\n",
       "         [ 1, 20, 38, 37],\n",
       "         [20, 38, 37, 37],\n",
       "         [38, 37, 37,  9],\n",
       "         [37, 37,  9, 54],\n",
       "         [37,  9, 54, 58],\n",
       "         [ 9, 54, 58,  6],\n",
       "         [ 1,  1,  1,  8],\n",
       "         [ 1,  1,  8, 39],\n",
       "         [ 1,  8, 39, 29],\n",
       "         [ 8, 39, 29, 15],\n",
       "         [39, 29, 15, 26],\n",
       "         [29, 15, 26, 15],\n",
       "         [15, 26, 15, 18],\n",
       "         [26, 15, 18, 28],\n",
       "         [ 1,  1,  1, 25],\n",
       "         [ 1,  1, 25,  6],\n",
       "         [ 1, 25,  6, 28],\n",
       "         [25,  6, 28, 38],\n",
       "         [ 6, 28, 38, 58],\n",
       "         [28, 38, 58, 15],\n",
       "         [38, 58, 15, 56],\n",
       "         [58, 15, 56, 28],\n",
       "         [15, 56, 28, 54],\n",
       "         [56, 28, 54, 18],\n",
       "         [28, 54, 18, 28],\n",
       "         [ 1,  1,  1, 21],\n",
       "         [ 1,  1, 21, 38],\n",
       "         [ 1, 21, 38, 31],\n",
       "         [21, 38, 31,  9],\n",
       "         [38, 31,  9,  2],\n",
       "         [31,  9,  2, 48],\n",
       "         [ 9,  2, 48, 15],\n",
       "         [ 2, 48, 15, 31],\n",
       "         [48, 15, 31, 28],\n",
       "         [ 1,  1,  1, 25],\n",
       "         [ 1,  1, 25, 37],\n",
       "         [ 1, 25, 37, 38],\n",
       "         [25, 37, 38,  2],\n",
       "         [37, 38,  2, 15],\n",
       "         [ 1,  1,  1, 16],\n",
       "         [ 1,  1, 16,  4],\n",
       "         [ 1, 16,  4, 56],\n",
       "         [16,  4, 56,  2],\n",
       "         [ 4, 56,  2, 54],\n",
       "         [56,  2, 54, 10],\n",
       "         [ 1,  1,  1, 41],\n",
       "         [ 1,  1, 41,  4],\n",
       "         [ 1, 41,  4, 56],\n",
       "         [41,  4, 56, 39],\n",
       "         [ 4, 56, 39, 37]]),\n",
       "  array([38, 19,  2, 28,  0, 18, 38, 39, 38,  9, 15,  0, 38, 37, 37,  9, 54,\n",
       "         58,  6,  0, 39, 29, 15, 26, 15, 18, 28,  0,  6, 28, 38, 58, 15, 56,\n",
       "         28, 54, 18, 28,  0, 38, 31,  9,  2, 48, 15, 31, 28,  0, 37, 38,  2,\n",
       "         15,  0,  4, 56,  2, 54, 10,  0,  4, 56, 39, 37, 15])),\n",
       " (array([[56, 39, 37, 15],\n",
       "         [39, 37, 15, 58],\n",
       "         [37, 15, 58,  6],\n",
       "         [15, 58,  6, 38],\n",
       "         [58,  6, 38, 31],\n",
       "         [ 6, 38, 31,  2],\n",
       "         [38, 31,  2, 54],\n",
       "         [31,  2, 54,  9],\n",
       "         [ 1,  1,  1, 53],\n",
       "         [ 1,  1, 53, 28],\n",
       "         [ 1, 53, 28, 37],\n",
       "         [53, 28, 37, 56],\n",
       "         [28, 37, 56, 54],\n",
       "         [37, 56, 54,  4],\n",
       "         [56, 54,  4, 56],\n",
       "         [54,  4, 56, 54],\n",
       "         [ 4, 56, 54, 37],\n",
       "         [56, 54, 37, 54],\n",
       "         [54, 37, 54, 10],\n",
       "         [ 1,  1,  1, 16],\n",
       "         [ 1,  1, 16,  4],\n",
       "         [ 1, 16,  4, 15],\n",
       "         [16,  4, 15, 56],\n",
       "         [ 4, 15, 56, 38],\n",
       "         [15, 56, 38,  4],\n",
       "         [56, 38,  4, 58],\n",
       "         [38,  4, 58, 28],\n",
       "         [ 4, 58, 28, 54],\n",
       "         [58, 28, 54, 31],\n",
       "         [ 1,  1,  1, 45],\n",
       "         [ 1,  1, 45, 10],\n",
       "         [ 1, 45, 10, 38],\n",
       "         [45, 10, 38, 54],\n",
       "         [10, 38, 54, 18],\n",
       "         [38, 54, 18, 38],\n",
       "         [54, 18, 38, 37],\n",
       "         [18, 38, 37, 28],\n",
       "         [38, 37, 28, 38],\n",
       "         [37, 28, 38,  4],\n",
       "         [28, 38,  4,  2],\n",
       "         [38,  4,  2, 28],\n",
       "         [ 1,  1,  1, 22],\n",
       "         [ 1,  1, 22, 54],\n",
       "         [ 1, 22, 54, 10],\n",
       "         [22, 54, 10, 28],\n",
       "         [ 1,  1,  1,  7],\n",
       "         [ 1,  1,  7, 31],\n",
       "         [ 1,  7, 31, 38],\n",
       "         [ 7, 31, 38,  4],\n",
       "         [31, 38,  4, 30],\n",
       "         [38,  4, 30, 38],\n",
       "         [ 4, 30, 38, 37],\n",
       "         [30, 38, 37, 37],\n",
       "         [ 1,  1,  1, 11],\n",
       "         [ 1,  1, 11, 38],\n",
       "         [ 1, 11, 38, 28],\n",
       "         [11, 38, 28,  9],\n",
       "         [38, 28,  9, 39],\n",
       "         [28,  9, 39, 10],\n",
       "         [ 1,  1,  1, 25],\n",
       "         [ 1,  1, 25,  6],\n",
       "         [ 1, 25,  6, 31],\n",
       "         [25,  6, 31, 39],\n",
       "         [ 6, 31, 39, 10]]),\n",
       "  array([58,  6, 38, 31,  2, 54,  9,  0, 28, 37, 56, 54,  4, 56, 54, 37, 54,\n",
       "         10,  0,  4, 15, 56, 38,  4, 58, 28, 54, 31,  0, 10, 38, 54, 18, 38,\n",
       "         37, 28, 38,  4,  2, 28,  0, 54, 10, 28,  0, 31, 38,  4, 30, 38, 37,\n",
       "         37,  0, 38, 28,  9, 39, 10,  0,  6, 31, 39, 10, 15])),\n",
       " (array([[31, 39, 10, 15],\n",
       "         [39, 10, 15, 10],\n",
       "         [10, 15, 10, 26],\n",
       "         [15, 10, 26, 28],\n",
       "         [10, 26, 28, 37],\n",
       "         [26, 28, 37, 28],\n",
       "         [28, 37, 28, 44],\n",
       "         [ 1,  1,  1, 41],\n",
       "         [ 1,  1, 41, 31],\n",
       "         [ 1, 41, 31,  2],\n",
       "         [41, 31,  2, 10],\n",
       "         [31,  2, 10, 58],\n",
       "         [ 2, 10, 58, 28],\n",
       "         [10, 58, 28, 38],\n",
       "         [58, 28, 38, 54],\n",
       "         [28, 38, 54, 10],\n",
       "         [ 1,  1,  1, 17],\n",
       "         [ 1,  1, 17, 39],\n",
       "         [ 1, 17, 39, 56],\n",
       "         [17, 39, 56, 58],\n",
       "         [39, 56, 58,  2],\n",
       "         [56, 58,  2, 38],\n",
       "         [58,  2, 38, 37],\n",
       "         [ 2, 38, 37, 37],\n",
       "         [38, 37, 37, 54],\n",
       "         [37, 37, 54, 10],\n",
       "         [ 1,  1,  1, 45],\n",
       "         [ 1,  1, 45, 31],\n",
       "         [ 1, 45, 31, 15],\n",
       "         [45, 31, 15, 37],\n",
       "         [31, 15, 37, 28],\n",
       "         [15, 37, 28,  3],\n",
       "         [37, 28,  3, 54],\n",
       "         [28,  3, 54, 10],\n",
       "         [ 1,  1,  1,  5],\n",
       "         [ 1,  1,  5, 58],\n",
       "         [ 1,  5, 58, 38],\n",
       "         [ 5, 58, 38, 31],\n",
       "         [58, 38, 31,  4],\n",
       "         [38, 31,  4, 54],\n",
       "         [31,  4, 54, 37],\n",
       "         [ 4, 54, 37, 28],\n",
       "         [ 1,  1,  1, 45],\n",
       "         [ 1,  1, 45, 39],\n",
       "         [ 1, 45, 39, 37],\n",
       "         [45, 39, 37, 28],\n",
       "         [39, 37, 28, 38],\n",
       "         [37, 28, 38, 54],\n",
       "         [28, 38, 54, 10],\n",
       "         [ 1,  1,  1, 41],\n",
       "         [ 1,  1, 41, 56],\n",
       "         [ 1, 41, 56,  6],\n",
       "         [41, 56,  6, 38],\n",
       "         [56,  6, 38, 37],\n",
       "         [ 6, 38, 37, 15],\n",
       "         [38, 37, 15,  2],\n",
       "         [37, 15,  2, 10],\n",
       "         [ 1,  1,  1, 22],\n",
       "         [ 1,  1, 22, 28],\n",
       "         [ 1, 22, 28, 26],\n",
       "         [22, 28, 26,  6],\n",
       "         [28, 26,  6,  2],\n",
       "         [26,  6,  2, 56],\n",
       "         [ 6,  2, 56, 38]]),\n",
       "  array([10, 26, 28, 37, 28, 44,  0, 31,  2, 10, 58, 28, 38, 54, 10,  0, 39,\n",
       "         56, 58,  2, 38, 37, 37, 54, 10,  0, 31, 15, 37, 28,  3, 54, 10,  0,\n",
       "         58, 38, 31,  4, 54, 37, 28,  0, 39, 37, 28, 38, 54, 10,  0, 56,  6,\n",
       "         38, 37, 15,  2, 10,  0, 28, 26,  6,  2, 56, 38, 31])),\n",
       " (array([[ 2, 56, 38, 31],\n",
       "         [56, 38, 31, 54],\n",
       "         [38, 31, 54, 10],\n",
       "         [ 1,  1,  1, 47],\n",
       "         [ 1,  1, 47, 38],\n",
       "         [ 1, 47, 38,  4],\n",
       "         [47, 38,  4, 10],\n",
       "         [38,  4, 10, 31],\n",
       "         [ 4, 10, 31, 54],\n",
       "         [10, 31, 54, 18],\n",
       "         [ 1,  1,  1, 45],\n",
       "         [ 1,  1, 45, 58],\n",
       "         [ 1, 45, 58,  2],\n",
       "         [45, 58,  2, 37],\n",
       "         [58,  2, 37, 15],\n",
       "         [ 2, 37, 15,  4],\n",
       "         [37, 15,  4, 15],\n",
       "         [15,  4, 15, 31],\n",
       "         [ 4, 15, 31,  6],\n",
       "         [15, 31,  6, 39],\n",
       "         [31,  6, 39,  4],\n",
       "         [ 6, 39,  4, 56],\n",
       "         [39,  4, 56,  6],\n",
       "         [ 4, 56,  6, 54],\n",
       "         [56,  6, 54, 10],\n",
       "         [ 1,  1,  1, 14],\n",
       "         [ 1,  1, 14, 37],\n",
       "         [ 1, 14, 37, 38],\n",
       "         [14, 37, 38, 26],\n",
       "         [37, 38, 26,  6],\n",
       "         [38, 26,  6, 28],\n",
       "         [26,  6, 28, 10],\n",
       "         [ 1,  1,  1, 40],\n",
       "         [ 1,  1, 40, 48],\n",
       "         [ 1, 40, 48, 15],\n",
       "         [40, 48, 15,  4],\n",
       "         [ 1,  1,  1, 14],\n",
       "         [ 1,  1, 14, 15],\n",
       "         [ 1, 14, 15, 10],\n",
       "         [14, 15, 10, 26],\n",
       "         [15, 10, 26,  6],\n",
       "         [10, 26,  6, 15],\n",
       "         [26,  6, 15, 31],\n",
       "         [ 6, 15, 31, 54],\n",
       "         [15, 31, 54, 10],\n",
       "         [ 1,  1,  1,  8],\n",
       "         [ 1,  1,  8, 38],\n",
       "         [ 1,  8, 38, 28],\n",
       "         [ 8, 38, 28, 31],\n",
       "         [38, 28, 31,  2],\n",
       "         [28, 31,  2,  4],\n",
       "         [31,  2,  4,  3],\n",
       "         [ 1,  1,  1, 16],\n",
       "         [ 1,  1, 16, 35],\n",
       "         [ 1, 16, 35, 38],\n",
       "         [16, 35, 38, 37],\n",
       "         [35, 38, 37, 37],\n",
       "         [38, 37, 37, 39],\n",
       "         [ 1,  1,  1, 41],\n",
       "         [ 1,  1, 41, 55],\n",
       "         [ 1, 41, 55, 54],\n",
       "         [41, 55, 54,  2],\n",
       "         [55, 54,  2, 37],\n",
       "         [54,  2, 37, 28]]),\n",
       "  array([54, 10,  0, 38,  4, 10, 31, 54, 18,  0, 58,  2, 37, 15,  4, 15, 31,\n",
       "          6, 39,  4, 56,  6, 54, 10,  0, 37, 38, 26,  6, 28, 10,  0, 48, 15,\n",
       "          4,  0, 15, 10, 26,  6, 15, 31, 54, 10,  0, 38, 28, 31,  2,  4,  3,\n",
       "          0, 35, 38, 37, 37, 39,  0, 55, 54,  2, 37, 28,  0])),\n",
       " (array([[ 1,  1,  1, 41],\n",
       "         [ 1,  1, 41, 37],\n",
       "         [ 1, 41, 37, 19],\n",
       "         [41, 37, 19, 28],\n",
       "         [37, 19, 28,  4],\n",
       "         [19, 28,  4,  3],\n",
       "         [ 1,  1,  1, 25],\n",
       "         [ 1,  1, 25, 15],\n",
       "         [ 1, 25, 15, 31],\n",
       "         [25, 15, 31, 56],\n",
       "         [15, 31, 56, 15],\n",
       "         [31, 56, 15, 31],\n",
       "         [56, 15, 31, 28],\n",
       "         [15, 31, 28, 44],\n",
       "         [ 1,  1,  1, 41],\n",
       "         [ 1,  1, 41, 38],\n",
       "         [ 1, 41, 38, 37],\n",
       "         [41, 38, 37, 37],\n",
       "         [38, 37, 37, 15],\n",
       "         [37, 37, 15, 26],\n",
       "         [37, 15, 26, 38],\n",
       "         [ 1,  1,  1, 16],\n",
       "         [ 1,  1, 16, 58],\n",
       "         [ 1, 16, 58, 54],\n",
       "         [16, 58, 54, 35],\n",
       "         [58, 54, 35, 15],\n",
       "         [54, 35, 15, 37],\n",
       "         [35, 15, 37, 15],\n",
       "         [ 1,  1,  1,  5],\n",
       "         [ 1,  1,  5, 58],\n",
       "         [ 1,  5, 58, 31],\n",
       "         [ 5, 58, 31, 28],\n",
       "         [58, 31, 28, 54],\n",
       "         [31, 28, 54, 10],\n",
       "         [ 1,  1,  1, 17],\n",
       "         [ 1,  1, 17,  2],\n",
       "         [ 1, 17,  2,  9],\n",
       "         [17,  2,  9,  2],\n",
       "         [ 2,  9,  2, 15],\n",
       "         [ 9,  2, 15, 35],\n",
       "         [ 2, 15, 35, 15],\n",
       "         [15, 35, 15, 28],\n",
       "         [35, 15, 28, 37],\n",
       "         [15, 28, 37, 28],\n",
       "         [ 1,  1,  1, 25],\n",
       "         [ 1,  1, 25, 39],\n",
       "         [ 1, 25, 39, 56],\n",
       "         [25, 39, 56,  6],\n",
       "         [39, 56,  6, 31],\n",
       "         [56,  6, 31, 38],\n",
       "         [ 6, 31, 38, 54],\n",
       "         [31, 38, 54, 10],\n",
       "         [ 1,  1,  1, 25],\n",
       "         [ 1,  1, 25, 15],\n",
       "         [ 1, 25, 15, 15],\n",
       "         [25, 15, 15, 35],\n",
       "         [ 1,  1,  1, 42],\n",
       "         [ 1,  1, 42,  2],\n",
       "         [ 1, 42,  2, 37],\n",
       "         [42,  2, 37, 58],\n",
       "         [ 2, 37, 58, 10],\n",
       "         [37, 58, 10,  6],\n",
       "         [58, 10,  6,  2],\n",
       "         [10,  6,  2, 31]]),\n",
       "  array([37, 19, 28,  4,  3,  0, 15, 31, 56, 15, 31, 28, 44,  0, 38, 37, 37,\n",
       "         15, 26, 38,  0, 58, 54, 35, 15, 37, 15,  0, 58, 31, 28, 54, 10,  0,\n",
       "          2,  9,  2, 15, 35, 15, 28, 37, 28,  0, 39, 56,  6, 31, 38, 54, 10,\n",
       "          0, 15, 15, 35,  0,  2, 37, 58, 10,  6,  2, 31, 38])),\n",
       " (array([[ 6,  2, 31, 38],\n",
       "         [ 1,  1,  1, 22],\n",
       "         [ 1,  1, 22,  6],\n",
       "         [ 1, 22,  6, 28],\n",
       "         [22,  6, 28, 19],\n",
       "         [ 6, 28, 19, 18],\n",
       "         [28, 19, 18, 15],\n",
       "         [19, 18, 15, 31],\n",
       "         [18, 15, 31,  4],\n",
       "         [15, 31,  4,  2],\n",
       "         [31,  4,  2, 10],\n",
       "         [ 1,  1,  1,  8],\n",
       "         [ 1,  1,  8, 38],\n",
       "         [ 1,  8, 38, 37],\n",
       "         [ 8, 38, 37, 38],\n",
       "         [38, 37, 38,  4],\n",
       "         [37, 38,  4, 18],\n",
       "         [38,  4, 18, 39],\n",
       "         [ 1,  1,  1,  8],\n",
       "         [ 1,  1,  8, 15],\n",
       "         [ 1,  8, 15,  4],\n",
       "         [ 8, 15,  4, 28],\n",
       "         [15,  4, 28, 58],\n",
       "         [ 4, 28, 58,  6],\n",
       "         [ 1,  1,  1, 32],\n",
       "         [ 1,  1, 32, 39],\n",
       "         [ 1, 32, 39, 37],\n",
       "         [32, 39, 37, 28],\n",
       "         [39, 37, 28, 10],\n",
       "         [ 1,  1,  1, 41],\n",
       "         [ 1,  1, 41,  3],\n",
       "         [ 1, 41,  3, 28],\n",
       "         [41,  3, 28,  9],\n",
       "         [ 3, 28,  9, 38],\n",
       "         [28,  9, 38, 18],\n",
       "         [ 9, 38, 18, 38],\n",
       "         [38, 18, 38, 10],\n",
       "         [ 1,  1,  1, 57],\n",
       "         [ 1,  1, 57, 28],\n",
       "         [ 1, 57, 28, 37],\n",
       "         [57, 28, 37, 28],\n",
       "         [28, 37, 28, 58],\n",
       "         [37, 28, 58, 28],\n",
       "         [ 1,  1,  1, 47],\n",
       "         [ 1,  1, 47, 54],\n",
       "         [ 1, 47, 54, 19],\n",
       "         [47, 54, 19, 54],\n",
       "         [54, 19, 54, 37],\n",
       "         [19, 54, 37, 28],\n",
       "         [ 1,  1,  1, 27],\n",
       "         [ 1,  1, 27, 38],\n",
       "         [ 1, 27, 38,  4],\n",
       "         [27, 38,  4, 18],\n",
       "         [38,  4, 18, 31],\n",
       "         [ 4, 18, 31, 15],\n",
       "         [18, 31, 15,  6],\n",
       "         [31, 15,  6, 39],\n",
       "         [15,  6, 39, 31],\n",
       "         [ 6, 39, 31, 28],\n",
       "         [39, 31, 28, 44],\n",
       "         [ 1,  1,  1, 25],\n",
       "         [ 1,  1, 25, 15],\n",
       "         [ 1, 25, 15, 38],\n",
       "         [25, 15, 38, 37]]),\n",
       "  array([ 0,  6, 28, 19, 18, 15, 31,  4,  2, 10,  0, 38, 37, 38,  4, 18, 39,\n",
       "          0, 15,  4, 28, 58,  6,  0, 39, 37, 28, 10,  0,  3, 28,  9, 38, 18,\n",
       "         38, 10,  0, 28, 37, 28, 58, 28,  0, 54, 19, 54, 37, 28,  0, 38,  4,\n",
       "         18, 31, 15,  6, 39, 31, 28, 44,  0, 15, 38, 37, 15]))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generator(_data, epochs=1, batch_size=64):\n",
    "    n = len(_data)\n",
    "    return generate_batch(loop(_data, epochs=epochs), batch_size=batch_size, n=None)\n",
    "\n",
    "\n",
    "data = list(generator(train, epochs=1, batch_size=64))\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 132)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def step_per_epoch(sequence, batch_size):\n",
    "    lengths = np.array([len(name[0]) for name in sequence])\n",
    "    return (sum(lengths) // batch_size) - 1\n",
    "\n",
    "from functools import reduce\n",
    "data = train[:100]\n",
    "batch_size = 6\n",
    "\n",
    "for i, (x, y) in enumerate(generator(data, epochs=1, batch_size=batch_size)):\n",
    "    pass\n",
    "\n",
    "i, step_per_epoch(data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is in place, so we can start the training!\n",
    "\n",
    "I'm going to monitor the progress of how the training is progressing by using the validation data.\n",
    "\n",
    "I'm also run the training for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "586/586 [==============================] - 13s 22ms/step - loss: 3.2588 - acc: 0.1383 - val_loss: 3.2023 - val_acc: 0.0851\n",
      "Epoch 2/50\n",
      "586/586 [==============================] - 9s 16ms/step - loss: 3.0574 - acc: 0.1389 - val_loss: 3.0157 - val_acc: 0.1721\n",
      "Epoch 3/50\n",
      "586/586 [==============================] - 10s 16ms/step - loss: 2.9690 - acc: 0.1778 - val_loss: 2.9072 - val_acc: 0.1917\n",
      "Epoch 4/50\n",
      "586/586 [==============================] - 10s 17ms/step - loss: 2.9285 - acc: 0.1752 - val_loss: 2.8376 - val_acc: 0.1632\n",
      "Epoch 5/50\n",
      "586/586 [==============================] - 10s 17ms/step - loss: 2.8646 - acc: 0.1982 - val_loss: 2.7714 - val_acc: 0.2011\n",
      "Epoch 6/50\n",
      "586/586 [==============================] - 10s 17ms/step - loss: 2.9076 - acc: 0.1775 - val_loss: 2.8077 - val_acc: 0.2022\n",
      "Epoch 7/50\n",
      "586/586 [==============================] - 11s 18ms/step - loss: 2.8963 - acc: 0.1906 - val_loss: 2.7795 - val_acc: 0.2019\n",
      "Epoch 8/50\n",
      "586/586 [==============================] - 11s 18ms/step - loss: 2.8460 - acc: 0.1913 - val_loss: 2.8118 - val_acc: 0.1735\n",
      "Epoch 9/50\n",
      "586/586 [==============================] - 11s 18ms/step - loss: 2.8200 - acc: 0.1961 - val_loss: 2.8210 - val_acc: 0.2215\n",
      "Epoch 10/50\n",
      "586/586 [==============================] - 11s 18ms/step - loss: 2.8010 - acc: 0.2131 - val_loss: 2.7400 - val_acc: 0.2092\n",
      "Epoch 11/50\n",
      "586/586 [==============================] - 11s 18ms/step - loss: 2.8731 - acc: 0.1835 - val_loss: 2.7541 - val_acc: 0.2027\n",
      "Epoch 12/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7801 - acc: 0.2059 - val_loss: 2.7245 - val_acc: 0.2195\n",
      "Epoch 13/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7898 - acc: 0.2111 - val_loss: 2.7415 - val_acc: 0.2262\n",
      "Epoch 14/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7541 - acc: 0.2182 - val_loss: 2.7137 - val_acc: 0.2252\n",
      "Epoch 15/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7646 - acc: 0.2230 - val_loss: 2.7226 - val_acc: 0.2229\n",
      "Epoch 16/50\n",
      "586/586 [==============================] - 11s 18ms/step - loss: 2.7833 - acc: 0.2245 - val_loss: 2.7154 - val_acc: 0.2327\n",
      "Epoch 17/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7917 - acc: 0.2009 - val_loss: 2.7391 - val_acc: 0.2045\n",
      "Epoch 18/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7696 - acc: 0.2121 - val_loss: 2.7303 - val_acc: 0.2186\n",
      "Epoch 19/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7449 - acc: 0.2201 - val_loss: 2.7454 - val_acc: 0.2335\n",
      "Epoch 20/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7362 - acc: 0.2186 - val_loss: 2.7067 - val_acc: 0.2251\n",
      "Epoch 21/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7662 - acc: 0.2193 - val_loss: 2.7477 - val_acc: 0.2307\n",
      "Epoch 22/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7423 - acc: 0.2274 - val_loss: 2.7426 - val_acc: 0.2298\n",
      "Epoch 23/50\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 2.7433 - acc: 0.2298 - val_loss: 2.6743 - val_acc: 0.2426\n",
      "Epoch 24/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7466 - acc: 0.2279 - val_loss: 2.7069 - val_acc: 0.2427\n",
      "Epoch 25/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7615 - acc: 0.2317 - val_loss: 2.7373 - val_acc: 0.2482\n",
      "Epoch 26/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7676 - acc: 0.2285 - val_loss: 2.6953 - val_acc: 0.2398\n",
      "Epoch 27/50\n",
      "586/586 [==============================] - 9s 16ms/step - loss: 2.7528 - acc: 0.2343 - val_loss: 2.6789 - val_acc: 0.2397\n",
      "Epoch 28/50\n",
      "586/586 [==============================] - 9s 16ms/step - loss: 2.7353 - acc: 0.2323 - val_loss: 2.6822 - val_acc: 0.2441\n",
      "Epoch 29/50\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 2.7171 - acc: 0.2299 - val_loss: 2.6706 - val_acc: 0.2446\n",
      "Epoch 30/50\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 2.7524 - acc: 0.2245 - val_loss: 2.6970 - val_acc: 0.2382\n",
      "Epoch 31/50\n",
      "586/586 [==============================] - 10s 17ms/step - loss: 2.8421 - acc: 0.2179 - val_loss: 2.8248 - val_acc: 0.2395\n",
      "Epoch 32/50\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 2.8071 - acc: 0.2226 - val_loss: 2.7185 - val_acc: 0.2403\n",
      "Epoch 33/50\n",
      "586/586 [==============================] - 9s 16ms/step - loss: 2.7731 - acc: 0.2306 - val_loss: 2.7143 - val_acc: 0.2368\n",
      "Epoch 34/50\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 2.7683 - acc: 0.2273 - val_loss: 2.6981 - val_acc: 0.2452\n",
      "Epoch 35/50\n",
      "586/586 [==============================] - 10s 18ms/step - loss: 2.7444 - acc: 0.2338 - val_loss: 2.6780 - val_acc: 0.2494\n",
      "Epoch 36/50\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 2.7334 - acc: 0.2350 - val_loss: 2.6709 - val_acc: 0.2524\n",
      "Epoch 37/50\n",
      "586/586 [==============================] - 8s 14ms/step - loss: 2.7200 - acc: 0.2386 - val_loss: 2.7278 - val_acc: 0.2355\n",
      "Epoch 38/50\n",
      "586/586 [==============================] - 10s 16ms/step - loss: 2.7495 - acc: 0.2385 - val_loss: 2.6783 - val_acc: 0.2601\n",
      "Epoch 39/50\n",
      "586/586 [==============================] - 9s 15ms/step - loss: 2.7245 - acc: 0.2473 - val_loss: 2.6556 - val_acc: 0.2559\n",
      "Epoch 40/50\n",
      "586/586 [==============================] - 10s 16ms/step - loss: 2.6921 - acc: 0.2495 - val_loss: 2.6497 - val_acc: 0.2559\n",
      "Epoch 41/50\n",
      "586/586 [==============================] - 11s 19ms/step - loss: 2.7564 - acc: 0.2390 - val_loss: 2.7226 - val_acc: 0.2584\n",
      "Epoch 42/50\n",
      "586/586 [==============================] - 11s 18ms/step - loss: 2.7319 - acc: 0.2394 - val_loss: 2.6654 - val_acc: 0.2606\n",
      "Epoch 43/50\n",
      "586/586 [==============================] - 10s 18ms/step - loss: 2.7044 - acc: 0.2466 - val_loss: 2.6452 - val_acc: 0.2603\n",
      "Epoch 44/50\n",
      "586/586 [==============================] - 12s 20ms/step - loss: 2.7068 - acc: 0.2458 - val_loss: 2.6364 - val_acc: 0.2532\n",
      "Epoch 45/50\n",
      "586/586 [==============================] - 14s 23ms/step - loss: 2.7004 - acc: 0.2454 - val_loss: 2.6542 - val_acc: 0.2654\n",
      "Epoch 46/50\n",
      "586/586 [==============================] - 14s 23ms/step - loss: 2.6942 - acc: 0.2431 - val_loss: 2.6419 - val_acc: 0.2563\n",
      "Epoch 47/50\n",
      "586/586 [==============================] - 15s 25ms/step - loss: 2.6866 - acc: 0.2474 - val_loss: 2.6303 - val_acc: 0.2684\n",
      "Epoch 48/50\n",
      "586/586 [==============================] - 13s 22ms/step - loss: 2.6930 - acc: 0.2491 - val_loss: 2.6607 - val_acc: 0.2649\n",
      "Epoch 49/50\n",
      "586/586 [==============================] - 13s 21ms/step - loss: 2.6641 - acc: 0.2561 - val_loss: 2.6936 - val_acc: 0.2656\n",
      "Epoch 50/50\n",
      "586/586 [==============================] - 13s 21ms/step - loss: 2.6599 - acc: 0.2551 - val_loss: 2.6230 - val_acc: 0.2654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0004310908>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "training = generator(train, epochs=epochs, batch_size=batch_size)\n",
    "training_steps = step_per_epoch(train, batch_size)\n",
    "\n",
    "validate = generator(valid, epochs=epochs, batch_size=batch_size)\n",
    "validate_steps = step_per_epoch(valid, batch_size)\n",
    "\n",
    "model.fit_generator(\n",
    "    training,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=training_steps,\n",
    "    validation_data=validate, \n",
    "    validation_steps=validate_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you might argue that 25% accuracy on predicting the next char is not that great but if you consider that this next char is predicted only by looking at the last 4 chars in the word and it can choose among 75 other characters, 25% looks decent enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to start by using a single starting char, padd it with 3 PADD_CHARs and feed it to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 11]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = index([PADD_CHAR]*3 + list('B')).tolist()\n",
    "seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the predictions that we geet.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.6201387 , -0.23826784,  0.5983277 , -0.10556627, -0.32646263,\n",
       "        -0.27480856,  0.12557875, -0.3414145 , -0.30603564, -0.06175375,\n",
       "        -0.35096955, -0.2666734 , -0.32480827, -0.25640425, -0.3097351 ,\n",
       "         1.0732597 , -0.27867168, -0.26669377, -0.2104237 , -0.08998151,\n",
       "        -0.32091066, -0.289114  , -0.28993937, -0.33924183, -0.32892138,\n",
       "        -0.2670479 , -0.38872594, -0.34774324,  1.4566476 , -0.11276225,\n",
       "        -0.19450927,  0.52868104, -0.3415661 , -0.29098564, -0.24209084,\n",
       "        -0.2599065 , -0.29484534,  0.37383062,  1.15111   ,  0.33651325,\n",
       "        -0.28981203, -0.24725765, -0.3549461 , -0.35660768, -0.2112373 ,\n",
       "        -0.28135416, -0.17757761, -0.30440184, -0.27851555, -0.27763483,\n",
       "        -0.3249073 , -0.32023948, -0.27075848, -0.27509457,  0.48936015,\n",
       "        -0.3275905 , -0.08906301, -0.28713107, -0.10081338]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict(np.array([seed[-window_size:]]))\n",
    "p "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we have to do now, is get the index of the largest prediction. That's our predicted char!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 11, 28]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_id = np.argmax(model.predict(np.array([seed[-window_size:]])))\n",
    "seed.append(char_id)\n",
    "seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to convert back to readable format we get that the predicted char is `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ba'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_string(indexed_word):\n",
    "    return \"\".join([id2voc[id] for id in indexed_word if id not in {0, 1}])\n",
    "\n",
    "to_string([1, 1, 1, 11, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to generate a full name, not only the next char, we can use the above model to continuusly generate characters, feed the predictions to the seed list and continue predicting including the last prediction in the input window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because every name in the dataset was suffixed with `STOP_CHAR` and we've trained on this format, the model will output `STOP_CHAR` as the next character if a given input window is considered to be the ending of a name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the basic strategy is looping on char predictions until we hit the `STOP_CHAR` as I've said above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fa\n",
      "Far\n",
      "Fara\n",
      "Fara\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Fara'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(start_char):\n",
    "    seed = index([PADD_CHAR]*3 + list(start_char)).tolist()\n",
    "    char_id = None\n",
    "    while char_id != voc2id[STOP_CHAR]:\n",
    "        predictions = model.predict(np.array([seed[-window_size:]]))\n",
    "        char_id = np.argmax(predictions)\n",
    "        seed.append(char_id)\n",
    "        print(to_string(seed))\n",
    "        \n",
    "    return to_string(seed)\n",
    "\n",
    "generate('F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non deterministic generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, using the basic strategy makes the generation deterministic (and limlted). This means that if I run `generate('F')` and I get `Fara`, I will get `Fara` every time I run `generate('F')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may be usefull in some cases but here we want the model to *imagine* multiple names, hoping that we hit a nice one, so we need some non-determinism in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to achieve this is that instead of considering the predicted char to be the one with the highest prediction, we can consider the top `k` chars, and randomly pick one of this as a prediction. \n",
    "\n",
    "For this to work reliably, `k` should be small because most of the predictions are roughly equal to the others. We only need the ones that have attached some significant probabilities attached to them as being the next chars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my case, I found through experimentation that `4` is a good-enough number for top candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Panola',\n",
       " 'Phalosese',\n",
       " 'Pelane',\n",
       " 'Penanianale',\n",
       " 'Phelereaniale',\n",
       " 'Panolananasas',\n",
       " 'Phereno',\n",
       " 'Phias',\n",
       " 'Palles',\n",
       " 'Phaloss']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def nd_generate(start_char):\n",
    "    seed = index([PADD_CHAR]*3 + list(start_char)).tolist()\n",
    "    char_id = None\n",
    "    best_candidates=4\n",
    "    while char_id != voc2id[STOP_CHAR]:\n",
    "        predictions = model.predict(np.array([seed[-window_size:]]))\n",
    "        candidates = np.argpartition(predictions[0], -best_candidates)[-best_candidates:]\n",
    "        char_id = random.choice(candidates)\n",
    "        seed.append(char_id)\n",
    "        \n",
    "    return to_string(seed)\n",
    "\n",
    "[nd_generate('P') for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code just produced 10 brand new names, starting with the letter 'P'. \n",
    "\n",
    "Note that indeed the names are not the same, but we still have some valid looking names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observation:* At this stage I can already see that the model is skewed twoards generating names that look more often than not, like latin/greek names.\n",
    "\n",
    "This happends I think because from the 5 datasets that I've used, 3 of them have this `ancient` characteristic: `animals`, `birds`, `mythology`. \n",
    "\n",
    "`LOTR` names also have a strange latin looking structure to them so the model has learned to represent names much more often in this format.\n",
    "\n",
    "To fix this we could sample more `family` names (eg. 3 times more) than the other and spend more time cleaning the `organisation` dataset and adding it back but at this stage, I've already spent most part of my weekend on this , so more than I should have. I'll leave it as such and maybe comeback at a later stage and fix it.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non deterministic generator with weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding non-deterministic behaviour really improved the genetation but I still have a problem: \n",
    "\n",
    "If I choose the 4 most probbable chars from the output, but the first two of them have a really high score, whereas the others are the best two in the remaining group of shallow predictions, picking one of these 4 at random, will make all equally probabile to be picked.\n",
    "\n",
    "In reality I want to model that the first two should be sampled way more often than the last two, keeping the proportional between them equal.\n",
    "\n",
    "This means random sampling by also using a probability distribution. Numpy has a `random.choice` implementation that allows this.\n",
    "\n",
    "I'll use `softmax` to convert the top most predictions to a valid probability distribution format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00932529, 0.01366176, 0.0315381 , 0.01560049, 0.01250847,\n",
       "       0.01317156, 0.01965727, 0.01232284, 0.01276661, 0.01629918,\n",
       "       0.01220565, 0.01327915, 0.01252918, 0.01341622, 0.01271947,\n",
       "       0.05071027, 0.01312078, 0.01327888, 0.01404751, 0.01584553,\n",
       "       0.01257811, 0.01298448, 0.01297377, 0.01234964, 0.01247775,\n",
       "       0.01327418, 0.0117534 , 0.0122451 , 0.0744045 , 0.01548863,\n",
       "       0.01427285, 0.02941632, 0.01232097, 0.0129602 , 0.01360963,\n",
       "       0.01336932, 0.01291027, 0.02519635, 0.05481582, 0.02427342,\n",
       "       0.01297542, 0.0135395 , 0.01215721, 0.01213703, 0.01403608,\n",
       "       0.01308563, 0.01451658, 0.01278748, 0.01312283, 0.01313439,\n",
       "       0.01252794, 0.01258656, 0.01322502, 0.0131678 , 0.02828209,\n",
       "       0.01249437, 0.01586009, 0.01301025, 0.01567482], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(pred):\n",
    "    return np.exp(pred) / np.sum(np.exp(pred))\n",
    "\n",
    "softmax(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pantosear',\n",
       " 'Possianilal',\n",
       " 'Phasa',\n",
       " 'Pheresaroas',\n",
       " 'Prate',\n",
       " 'Palananose',\n",
       " 'Paten',\n",
       " 'Ponolusx',\n",
       " 'Palenania',\n",
       " 'Phastarearisu']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import random\n",
    "\n",
    "def softmax(pred):\n",
    "    return np.exp(pred) / np.sum(np.exp(pred))\n",
    "\n",
    "def nd_generate_weights(start_char):\n",
    "    seed = index([PADD_CHAR]*3 + list(start_char)).tolist()\n",
    "    char_id = None\n",
    "    best_candidates=5\n",
    "    while char_id != voc2id[STOP_CHAR]:\n",
    "        predictions = model.predict(np.array([seed[-window_size:]]))\n",
    "        candidates = np.argpartition(predictions[0], -best_candidates)[-best_candidates:]\n",
    "        weights = softmax(predictions[0][candidates])\n",
    "        char_id = random.choice(candidates, p=weights)\n",
    "        seed.append(char_id)\n",
    "        \n",
    "    return to_string(seed)\n",
    "\n",
    "[nd_generate_weights('P') for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not that obvious, but to me these results look better than the previous ones!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enforcing Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other requirement was to allos the marketing team to enfore a certain structure on the generation process (`Inclusion of specific sub string within the name`)\n",
    "\n",
    "This means two things:\n",
    "* Allowing for a predefined prefix\n",
    "* Allowing for a predefined substring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enforcing a prefix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may come as a surprise but we already have this! Our model, can be seeded with a single letter as we've been doing until now, but we can also pass a full prefix string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comatinos'"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_generate_weights(\"Com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass an arbitrarily long sequence, but the predictions will only be made on the last 4 chars. Remember that the input to the model is only 4 chars in length.\n",
    "\n",
    "This limits a bit the expresiveness but it's actually quite robust if you try it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enforcing a length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For enabling a certain length we will ad the option of specifying a pattern to our name, by adding `wild-char` capabilities.\n",
    "\n",
    "Essentialy, we will add a special symbol allowable in the seed, and scan the given seed from left to right. Depending on the current seed char that we're processing we'll do two things:\n",
    "* if the next char in the seed is a `wild-char` predict the char using the model and add it to the seed.\n",
    "* if the next char in the seed is a normal char, put that directly into the seed without doing a prediction (it's a fixed char).\n",
    "\n",
    "We will do this until the seed list is exhausted and continue genrating as before until we hit a `STOP_CHAR`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beautifull thing is, is that at this point we can also use the `STOP_CHAR` itself in the seed pattern, specifying that the generation of the name should stop as soon as we exhaust the seed list (i.e. we can pass `Run...io|` and this will predict only the inlined 3 `wild-char` caracters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inos'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_generate_weights(\"inos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kaynca'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WILD_CHAR = \".\"\n",
    "\n",
    "def predict_char(model, seed, window_size, best_candidates):\n",
    "    predictions = model.predict(np.array([seed[-window_size:]]))\n",
    "    candidates = np.argpartition(predictions[0], -best_candidates)[-best_candidates:]\n",
    "    weights = softmax(predictions[0][candidates])\n",
    "    char_id = random.choice(candidates, p=weights)\n",
    "    return char_id\n",
    "\n",
    "def nd_generate_weights_with_wildcards(start_char):\n",
    "    best_candidates=5    \n",
    "    seed = index([PADD_CHAR]*3 + list(start_char[0])).tolist()\n",
    "    \n",
    "    # Traverse the seeding chars\n",
    "    for i, wanted_char in enumerate(start_char[1:]):\n",
    "        if wanted_char == WILD_CHAR:\n",
    "            seed.append(predict_char(model, seed, window_size, best_candidates))\n",
    "        else:\n",
    "            seed.append(voc2id[wanted_char])\n",
    "            \n",
    "    # Traverse until the EOS\n",
    "    while seed[-1] != voc2id[STOP_CHAR]:\n",
    "        seed.append(predict_char(model, seed, window_size, best_candidates))\n",
    "        \n",
    "    return to_string(seed)\n",
    "\n",
    "nd_generate_weights_with_wildcards(\"K.y.c..|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have control over the internal structure, the prefix, and the length. As a side benefit we can also specify the suffix as well (i.e. we can generate stuff ending in something popular as `.io`, `.ly` or `.ai`)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensuring name can be registered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last piece would be to generated `unique` names, and also ones that can be trade-mark-able (assuming these to be names that don't have a domain registered for them).\n",
    "\n",
    "The uniqueness part means that we don't directly reproduce names from our dataset and this can be easily implemented by cycling until we have a name that's outside of it.\n",
    "\n",
    "At this stage we can also pass a list of registered domain names and make sure all the generations are not registered! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Coolachuio',\n",
       " 'Coolapario',\n",
       " 'Coolaseio',\n",
       " 'Coolasuio',\n",
       " 'Coolipanio',\n",
       " 'Coolonio',\n",
       " 'Coolonsio',\n",
       " 'Coolopaio',\n",
       " 'Coolosio',\n",
       " 'Coolumoio'}"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen_new_name(seed, knwon_names, already_generated):\n",
    "    name = None\n",
    "    while name is None or name in knwon_names or name in already_generated:\n",
    "        name = nd_generate_weights_with_wildcards(seed)\n",
    "    already_generated.add(name)\n",
    "    \n",
    "def gen_new_names(seed, count, knwon_names):\n",
    "    generated_names = set()\n",
    "    for i in range(count):\n",
    "        gen_new_name(seed, knwon_names, generated_names)\n",
    "    return generated_names\n",
    "    \n",
    "registered_domains = set(all_names.flatten().tolist())\n",
    "gen_new_names(\"Cool....io|\", 10, registered_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note that I took a shortcut and considered everything in the initial database as registered names. Ideally one would compile a dataset with all registered domains and pass in that. Since this take some effort, I'll say pass on this.* \n",
    "\n",
    "*Either this or replace the `name in known_names` with a on the fly check that the domain is available. There are APIs for that, it's doable.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using this to predict good names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the business that I work at has lots of it's workflows tied to names, I'll try to generate a bunch of names that start with `Nam`.\n",
    "\n",
    "I also want the name to be rather short (6 chars max) and not be registered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Namani',\n",
       " 'Namas',\n",
       " 'Namele',\n",
       " 'Namelu',\n",
       " 'Namena',\n",
       " 'Names',\n",
       " 'Namial',\n",
       " 'Namipo',\n",
       " 'Namnas',\n",
       " 'Namnop'}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_new_names(\"Nam...|\", 10, registered_domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also funny to see what the model does with the abbreviation of the current name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Comoro', 'Adviso')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_generate_weights(\"Com\"), nd_generate_weights(\"Adv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Name. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to win the challenge I have to make a proposition. \n",
    "\n",
    "Since the company deals with names, and since this blog entry also focused lots of attention on names, I'll seed the generator with `Name` to see what we get...\n",
    "\n",
    "Dum dum dum!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Namera'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nd_generate_weights(\"Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Namera`** this is it! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this name wins, and you'll see a billion dollar company with this name in the future, you'll know where it came from and how was it obtained.\n",
    "\n",
    "This is the age of ML."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
